{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwlZ6BT6W2nL"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "#X=X[y!=2]\n",
        "#y=y[y!=2]\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "# which is importance for convergence of the neural network\n",
        "#scaler = StandardScaler()\n",
        "scaler = MinMaxScaler((-3.142, 3.142))\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "Ik_WILWmXF9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 4\n",
        "num_layers = 1\n",
        "bond = 16"
      ],
      "metadata": {
        "id": "NgaUMsuUXH4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = VQC(num_qubits,num_layers)\n",
        "optimizer = torch.optim.Adam(model_test.parameters(), lr = 0.01, weight_decay=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "EPOCHS = 25\n",
        "X_train = (torch.from_numpy(X_train_0)).float()\n",
        "y_train = (torch.from_numpy(y_train_0)).long().reshape(X_train.shape[0],1)\n",
        "X_test  = Variable(torch.from_numpy(X_test_0)).float()\n",
        "y_test  = Variable(torch.from_numpy(y_test_0)).long().reshape(X_test.shape[0],1)\n",
        "model_test.train()\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "accuracy_list_train = np.zeros((EPOCHS,))\n",
        "\n",
        "for epoch in tqdm.trange(EPOCHS):\n",
        "  l = 0\n",
        "  c = []\n",
        "  for b,s in enumerate(X_train):\n",
        "    psi = create_zero_tensor(num_qubits, bond)\n",
        "    k1 = F.softmax(model_test(psi,s), dim = 1)\n",
        "    loss = F.cross_entropy(k1, y_train[b])\n",
        "    correct = (torch.argmax(k1, dim=1) == y_train[b]).type(torch.FloatTensor)\n",
        "    c.append(correct.item())\n",
        "    l+=loss/4\n",
        "    if int((b+1)%4)==0:\n",
        "      optimizer.zero_grad()\n",
        "      l.backward(create_graph = True)\n",
        "      optimizer.step()\n",
        "      loss_list[epoch] = l.item()\n",
        "      loss_epoch = float(l)\n",
        "      l=torch.zeros(1)\n",
        "    accuracy_list_train[epoch] = np.array(c).mean()\n",
        "  with torch.no_grad():\n",
        "    c=[]\n",
        "    for j,s in enumerate(X_test):\n",
        "      psi = create_zero_tensor(num_qubits, bond)\n",
        "      k1 = F.softmax(model_test(psi,s), dim = 1)\n",
        "      correct = (torch.argmax(k1, dim=1) == y_test[j]).type(torch.FloatTensor)\n",
        "      c.append(correct.item())\n",
        "    accuracy_list[epoch] = np.array(c).mean()\n",
        "  print(\"Train Loss: {0:1.4f}; Train Accuracy: {1:1.4f}; Test Accuracy: {2:1.4f}\".format(loss_epoch, accuracy_list_train[epoch], accuracy_list[epoch]))\n"
      ],
      "metadata": {
        "id": "Shs10L9jXJvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}