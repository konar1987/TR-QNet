{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "! pip install tensorly\n",
        "import tensorly as tl\n",
        "from torch.autograd import Variable\n",
        "tl.set_backend('pytorch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSyId6LSqJbg",
        "outputId": "1b6b9fa8-8915-4939-c81d-a982973620ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly\n",
            "  Downloading tensorly-0.8.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.10.1)\n",
            "Installing collected packages: tensorly\n",
            "Successfully installed tensorly-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGuK142Ru_W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "plt.style.use('ggplot')\n",
        "from fastai.basics import *"
      ],
      "metadata": {
        "id": "23tur1lJPNo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iS15BmNwSG8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "AUDnz3fNSHTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shy8UNEySLQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST('classifier_data', train=True, download=True)\n",
        "train_indices = (train_dataset.targets == 3) | (train_dataset.targets == 7)\n",
        "data, targets = train_dataset.data[train_indices], train_dataset.targets[train_indices]\n",
        "# print(data)\n",
        "# print(targets)"
      ],
      "metadata": {
        "id": "riBHif6bSLgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19916647-ab56-4c68-d72f-2eaa112fa58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to classifier_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 75963733.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting classifier_data/MNIST/raw/train-images-idx3-ubyte.gz to classifier_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to classifier_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 78253032.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting classifier_data/MNIST/raw/train-labels-idx1-ubyte.gz to classifier_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to classifier_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25725795.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting classifier_data/MNIST/raw/t10k-images-idx3-ubyte.gz to classifier_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to classifier_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4522917.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting classifier_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to classifier_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2j5gZTVST4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#QIKSIT TRAINING\n",
        "\n",
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning\n",
        "from qiskit import QuantumCircuit, assemble, Aer\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "import qiskit\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.circuit.library import  RealAmplitudes, EfficientSU2, TwoLocal, NLocal\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B, ADAM"
      ],
      "metadata": {
        "id": "lX-r4fMaX2Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZOsOAC5X29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FeatureMap():\n",
        "  num_qubits = 4\n",
        "  x = ParameterVector('x', length = num_qubits)\n",
        "  feature_map = QuantumCircuit(num_qubits)\n",
        "\n",
        "  for i in range(num_qubits):\n",
        "    feature_map.rx(x[i],i)\n",
        "    feature_map.h(i)\n",
        "  return feature_map"
      ],
      "metadata": {
        "id": "yBU-vD_8X3GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library.n_local import real_amplitudes\n",
        "def VarCirc():\n",
        "  num_qubits = 4\n",
        "  #var_circuit = TwoLocal(4, ['rx', 'ry','rz'], 'cx', entanglement = 'circular', reps = 1, insert_barriers = True)\n",
        "  reps = 3\n",
        "\n",
        "  psi = ParameterVector('psi', length = num_qubits*reps*3)\n",
        "  var_circuit = QuantumCircuit(num_qubits)\n",
        "\n",
        "  for j in range(reps):\n",
        "    for i in range(num_qubits-1):\n",
        "      var_circuit.cx(i,i+1)\n",
        "    var_circuit.cx(num_qubits-1, 0)\n",
        "\n",
        "    for i in range(num_qubits):\n",
        "      var_circuit.rx(psi[3*i + 0 + num_qubits*3*j], i)\n",
        "      var_circuit.ry(psi[3*i + 1 + num_qubits*3*j], i)\n",
        "      var_circuit.rz(psi[3*i + 2 + num_qubits*3*j], i)\n",
        "\n",
        "  return var_circuit"
      ],
      "metadata": {
        "id": "KoyVmLyKX9VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "subset_i = random.sample(range(len(data)), 100)\n",
        "data = data[subset_i]\n",
        "targets = targets[subset_i]"
      ],
      "metadata": {
        "id": "m2NMmAPbSUgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reshape(len(data), 784)\n",
        "targets = np.array([int(i==7) for i in targets])\n",
        "# print(data)\n",
        "# print(targets)"
      ],
      "metadata": {
        "id": "-pDSLnghx9GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVCc5_DVo6uu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "class TNLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TNLayer, self).__init__()\n",
        "        # Create the variables for the layer.\n",
        "        self.a_var = nn.Parameter(torch.randn(28, 28, 2) * (1.0 / 28.0))\n",
        "        self.b_var = nn.Parameter(torch.randn(28, 28, 2) * (1.0 / 28.0))\n",
        "        self.bias = nn.Parameter(torch.zeros(28, 28))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Define the contraction.\n",
        "        def f(input_vec, a_var, b_var, bias_var):\n",
        "            # Reshape to a matrix instead of a vector.\n",
        "            input_vec = input_vec.reshape(28, 28)\n",
        "             #input_vec = input_vec.reshape(2, 512)\n",
        "\n",
        "            # Now we create the network.\n",
        "            a = a_var.unsqueeze(0)  # Shape: (1, 32, 32, 2)\n",
        "            b = b_var.unsqueeze(0)  # Shape: (1, 32, 32, 2)\n",
        "            x_node = input_vec.unsqueeze(-1)  # Shape: (32, 32, 1)\n",
        "\n",
        "            # Contract a with x_node\n",
        "            c = torch.einsum(\"ijkl,ijm->ijkm\", a, x_node)  # Shape: (32, 32, 32, 2)\n",
        "\n",
        "            # Contract the result with b\n",
        "            result = torch.einsum(\"ijkl,ijkl->ij\", c, b)  # Shape: (32, 32)\n",
        "\n",
        "            # Finally, add bias.\n",
        "            return result + bias_var\n",
        "\n",
        "        # To deal with a batch of items, loop through the input batch.\n",
        "        results = []\n",
        "        for input_vec in inputs:\n",
        "            results.append(f(input_vec, self.a_var, self.b_var, self.bias))\n",
        "        return nn.functional.relu(torch.stack(results))\n",
        "\n",
        "\n",
        "\n",
        "class VQC(nn.Module):\n",
        "  def __init__(self, n, num_layers):\n",
        "    super(VQC, self).__init__()\n",
        "    self.n = n\n",
        "    self.num_layers = num_layers\n",
        "    self.params = nn.Parameter(torch.randn(self.n, 3 * self.num_layers))\n",
        "\n",
        "  def prints(self, psi):\n",
        "    print(\"-------------------------MPS STRUCTURE SHAPE------------------------------------------\")\n",
        "    for _, i in enumerate(psi):\n",
        "      print(i.shape)\n",
        "    print(\"-------------------------SHAPE------------------------------------------\")\n",
        "\n",
        "  def H(self, i, psi):\n",
        "    H_matrix = 1 / ((2) ** 0.5) * torch.tensor([[1, 1],\n",
        "                                                 [1, -1]], dtype=torch.cfloat)\n",
        "    psi[i] = torch.tensordot(H_matrix, psi[i], ([1], [2]))\n",
        "    psi[i] = torch.moveaxis(psi[i], 0, 2)\n",
        "    return psi\n",
        "\n",
        "  def RX(self, i, j, psi):  # Alter the array psi into the array where H has acted on the ith qubit\n",
        "    t1 = (torch.cos(i / 2)).reshape(1)\n",
        "    t2=(torch.sin(i/2)*-1j).reshape(1)\n",
        "    t3=(torch.sin(i/2)*-1j).reshape(1)\n",
        "    t4=(torch.cos(i/2)).reshape(1)\n",
        "    f1=torch.cat([t1,t2])\n",
        "    f2=torch.cat([t3,t4])\n",
        "    rx=torch.cat([f1,f2]).reshape(2,2).type(torch.cfloat)\n",
        "    psi[j]=torch.tensordot(rx,psi[j],([1],[2]))\n",
        "    psi[j]=torch.moveaxis(psi[j],0,2)\n",
        "    return psi\n",
        "  def RY(self,i,j,psi): # Alter the array psi into the array where H has acted on the ith qubit\n",
        "    t1=(torch.cos(i/2)).reshape(1)\n",
        "    t2=-1.*(torch.sin(i/2)).reshape(1)\n",
        "    t3=(torch.sin(i/2)).reshape(1)\n",
        "    t4=(torch.cos(i/2)).reshape(1)\n",
        "    f1=torch.cat([t1,t2])\n",
        "    f2=torch.cat([t3,t4])\n",
        "    ry=torch.cat([f1,f2]).reshape(2,2).type(torch.cfloat)\n",
        "    psi[j]=torch.tensordot(ry,psi[j],([1],[2]))\n",
        "    psi[j]=torch.moveaxis(psi[j],0,2)\n",
        "    return psi\n",
        "\n",
        "  def RZ(self,i,j,psi): # Alter the array psi into the array where H has acted on the ith qubit\n",
        "    t1=(torch.exp(-1j*i/2)).reshape(1)\n",
        "    t2=(torch.zeros(1)).reshape(1)\n",
        "    t3=(torch.zeros(1)).reshape(1)\n",
        "    t4=(torch.exp(1j*i/2)).reshape(1)\n",
        "    f1=torch.cat([t1,t2])\n",
        "    f2=torch.cat([t3,t4])\n",
        "    rz=torch.cat([f1,f2]).reshape(2,2).type(torch.cfloat)\n",
        "    psi[j]=torch.tensordot(rz,psi[j],([1],[2]))\n",
        "    psi[j]=torch.moveaxis(psi[j],0,2)\n",
        "    return psi\n",
        "\n",
        "  def CNOT(self, i, j, psi):\n",
        "     dim = psi[i].shape[0]\n",
        "     mps=torch.tensordot(psi[i],psi[j],([1],[0]))\n",
        "     mps=torch.moveaxis(mps,2,1)\n",
        "     CNOT_matrix=torch.tensor([[1,0,0,0],\n",
        "                       [0,1,0,0],\n",
        "                       [0,0,0,1],\n",
        "                       [0,0,1,0]],dtype=torch.cfloat)\n",
        "     CNOT_tensor=torch.reshape(CNOT_matrix, (2,2,2,2))\n",
        "     mps=torch.tensordot(CNOT_tensor, mps, ([2,3],[2, 3]))\n",
        "     mps=torch.moveaxis(mps,1,3).reshape((2*dim,2*dim))\n",
        "     #mps+=mps+(torch.randn(mps.shape))*0.001\n",
        "     data=torch.rand(mps.shape)\n",
        "     data=data*mps.abs().max()*0.000001/data.max()\n",
        "     mps=mps+data\n",
        "     #u,s,v = torch.linalg.svd(mps)\n",
        "     u,s,v = torch.svd(mps)\n",
        "     v = torch.conj(v.T)\n",
        "     c = torch.diag(s[:dim])\n",
        "     mps1 = torch.mm(u[:,:dim], c.type(torch.cfloat))\n",
        "     mps1 = mps1.reshape((2,dim, dim))\n",
        "     psi[i] = torch.moveaxis(mps1,0,2)\n",
        "     mps2 = v[:dim,:]\n",
        "     psi[j] = mps2.reshape((dim, dim,2))\n",
        "     return psi\n",
        "\n",
        "  def CNOT_full(self,i,j,psi):\n",
        "        # Alter the array psi into the array where H has acted on the ith qubit\n",
        "        #i-->control;\n",
        "        #j-->target;\n",
        "        s0=psi[i].shape[0]\n",
        "        s1=psi[j].shape[1]\n",
        "        # print(i,j)\n",
        "        # print(psi[i].shape)\n",
        "        # print(psi[j].shape)\n",
        "        mps=torch.tensordot(psi[i],psi[j],([1],[0]))\n",
        "        mps=torch.moveaxis(mps,2,1)\n",
        "        #print(mps.shape)\n",
        "        CNOT_matrix=torch.tensor([[1,0,0,0],\n",
        "                      [0,1,0,0],\n",
        "                      [0,0,0,1],\n",
        "                      [0,0,1,0]],dtype=torch.cfloat)\n",
        "\n",
        "        CNOT_tensor=torch.reshape(CNOT_matrix, (2,2,2,2))\n",
        "        mps=torch.tensordot(CNOT_tensor, mps, ([2,3],[2,3]))\n",
        "        mps=torch.moveaxis(mps,1,3).reshape((s0*2,s1*2))\n",
        "        data=torch.rand(mps.shape)\n",
        "        data=data*mps.abs().max()*0.00001/data.max()\n",
        "        mps=mps+data\n",
        "        u, s, v =  torch.linalg.svd(mps)\n",
        "        c=(torch.zeros(u.shape[1],v.shape[0]))\n",
        "        for h,k in enumerate(s):\n",
        "          c[h,h]=k\n",
        "        mps1=torch.mm(u, c.type(torch.cfloat))\n",
        "        mps1=mps1.reshape((2,int(mps1.shape[0]/2),mps1.shape[1]))\n",
        "        psi[i]=torch.moveaxis(mps1,0,2)\n",
        "        mps2=v#.transpose(-2, -1)\n",
        "        psi[j]=mps2.reshape((mps2.shape[0],int(mps2.shape[1]/2),2))\n",
        "        return psi\n",
        "\n",
        "  def getParams(self):\n",
        "    return self.params\n",
        "\n",
        "  def setParams(self, params_matrix):\n",
        "    self.params = params_matrix\n",
        "\n",
        "  def compute_tensor_circuit(self, psi, t):\n",
        "    #Embedding layer\n",
        "    for i in range(self.n):\n",
        "      self.RX(t[i], i, psi)\n",
        "      self.H(i, psi)\n",
        "\n",
        "    # Parametrized Layers\n",
        "    #Each layer contains a series of parametrized RX, RY, RZ gates and cyclic entanglement\n",
        "    for i in range(self.num_layers):\n",
        "      #CNOTs\n",
        "      for j in range(self.n-1):\n",
        "        psi = self.CNOT(j, j+1, psi)\n",
        "      psi = self.CNOT(self.n-1,0, psi)\n",
        "\n",
        "      #Parametrized rotations\n",
        "      for j in range(self.n):\n",
        "        psi =self.RX(self.params[j][3*i + 0], j, psi)\n",
        "        psi = self.RY(self.params[j][3*i + 1], j, psi)\n",
        "        psi = self.RZ(self.params[j][3*i + 2], j, psi)\n",
        "\n",
        "    return psi\n",
        "\n",
        "  def contract_tensor_ring(self,psi):\n",
        "    psi_new = psi[0]\n",
        "    for i in range(self.n-2):\n",
        "      psi_new = torch.tensordot(psi_new, psi[i+1], ([1], [0]))\n",
        "      psi_new = torch.moveaxis(psi_new, -2, 1)\n",
        "\n",
        "    psi_new = torch.tensordot(psi_new, psi[self.n-1], ([0,1], [1,0]))\n",
        "    return psi_new\n",
        "\n",
        "  # def FeatureMap():\n",
        "  #   num_qubits = 4\n",
        "  #   x = ParameterVector('x', length = num_qubits)\n",
        "  #   feature_map = QuantumCircuit(num_qubits)\n",
        "\n",
        "  #   for i in range(num_qubits):\n",
        "  #      feature_map.rx(x[i],i)\n",
        "  #      feature_map.h(i)\n",
        "  #   return feature_map\n",
        "\n",
        "  # def VarCirc():\n",
        "  #    num_qubits = 4\n",
        "  # #var_circuit = TwoLocal(4, ['rx', 'ry','rz'], 'cx', entanglement = 'circular', reps = 1, insert_barriers = True)\n",
        "  #    reps = 3\n",
        "\n",
        "  #    psi = ParameterVector('psi', length = num_qubits*reps*3)\n",
        "  #    var_circuit = QuantumCircuit(num_qubits)\n",
        "\n",
        "  #    for j in range(reps):\n",
        "  #     for i in range(num_qubits-1):\n",
        "  #        var_circuit.cx(i,i+1)\n",
        "  #        var_circuit.cx(num_qubits-1, 0)\n",
        "\n",
        "  #    for i in range(num_qubits):\n",
        "  #     var_circuit.rx(psi[3*i + 0 + num_qubits*3*j], i)\n",
        "  #     var_circuit.ry(psi[3*i + 1 + num_qubits*3*j], i)\n",
        "  #     var_circuit.rz(psi[3*i + 2 + num_qubits*3*j], i)\n",
        "\n",
        "  #    return var_circuit\n",
        "\n",
        "\n",
        "  def forward(self, psi, t):\n",
        "\n",
        "    # Convert tensor t to complex tensor\n",
        "    # print(t.size())\n",
        "    # t_complex = torch.view_as_complex(t)\n",
        "    # print(t_complex.size())\n",
        "    psi_final = self.compute_tensor_circuit(psi, t)\n",
        "    k = self.contract_tensor_ring(psi_final)\n",
        "    k1 = k[0, 0, 0, 0].abs().reshape(1) ** 2\n",
        "    k2 = k[0, 0, 1, 0].abs().reshape(1) ** 2\n",
        "    k3 = k[1, 1, 1, 1].abs().reshape(1) ** 2\n",
        "\n",
        "    return torch.cat([k1, k2, k3]).reshape(1, 3)\n",
        "\n",
        "  def final_state(self, psi,t):\n",
        "\n",
        "    #psi_final = self.test_circuit(psi,t)\n",
        "    psi_final = self.compute_tensor_circuit(psi, t)\n",
        "    k = self.contract_tensor_ring(psi_final)\n",
        "    return k\n",
        "\n",
        "  def create_zero_tensor(num_qubits, d):\n",
        "    psi_0 = []\n",
        "    for j in range(num_qubits):\n",
        "      k = torch.zeros((d,d,2), dtype=torch.cfloat)\n",
        "      k[0,0,0] = 1.0\n",
        "      psi_0.append(k)\n",
        "    return psi_0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.utils import QuantumInstance, algorithm_globals\n",
        "backend = Aer.get_backend('aer_simulator_matrix_product_state')\n",
        "backend_options = {\"method\": \"statevector\"}\n",
        "seed = 987\n",
        "quantum_instance = QuantumInstance(backend, shots=1024,seed_simulator = seed, seed_transpiler = seed,\n",
        "                                   backend_options=backend_options)"
      ],
      "metadata": {
        "id": "S4dknCehu9VP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1263d4a-e61a-4487-a888-d4111cb4cc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3721013baf0a>:5: DeprecationWarning: The class ``qiskit.utils.quantum_instance.QuantumInstance`` is deprecated as of qiskit-terra 0.24.0. It will be removed no earlier than 3 months after the release date. For code migration guidelines, visit https://qisk.it/qi_migration.\n",
            "  quantum_instance = QuantumInstance(backend, shots=1024,seed_simulator = seed, seed_transpiler = seed,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# num_qubits = 4\n",
        "# X = StandardScaler().fit_transform(data)\n",
        "# pca = PCA(num_qubits)\n",
        "# X = pca.fit_transform(X)\n",
        "\n",
        "# scaler = MinMaxScaler((-3.142, 3.142))\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "# X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(\n",
        "# X_scaled, targets, test_size=0.25, random_state=2)"
      ],
      "metadata": {
        "id": "IE8-RtV8o7w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNeuralNetwork, self).__init__()\n",
        "        self.tn_layer = TNLayer()\n",
        "        self.vqc = VQC(4, 2)\n",
        "        #self.vqc = VQC(feature_map=FeatureMap(), ansatz=VarCirc(), loss=\"cross_entropy\", optimizer= COBYLA(maxiter=50), quantum_instance=quantum_instance,)\n",
        "        #self.output_layer = nn.Linear(2, 2)  # Adjust the output layer to match the number of classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tn_layer(x)\n",
        "        #print(x.shape)\n",
        "        x = x.reshape(len(x), 784)\n",
        "        #print(x.shape)\n",
        "        #print(\"++++++\")\n",
        "        #print(x)\n",
        "        scaler = MinMaxScaler((-3.142, 3.142))\n",
        "        y = StandardScaler().fit_transform(x)\n",
        "        pca = PCA(4)\n",
        "        X1 = pca.fit_transform(y)\n",
        "        X_scaled = scaler.fit_transform(X1)\n",
        "        X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_scaled, targets, test_size=0.25, random_state=2)\n",
        "        #print(X1.shape)\n",
        "        print(\"++++++\")\n",
        "        #print(X1[0])\n",
        "        Y1 =[]\n",
        "        for i in range(100):\n",
        "        #X1 = self.vqc(VQC.create_zero_tensor(4, 2), X1.view(X1.shape[0], -1))\n",
        "           Y1.append(self.vqc(VQC.create_zero_tensor(4, 2), torch.tensor(X1[i])))\n",
        "        #X1 = self.vqc(VQC.create_zero_tensor(4, 2), X1)\n",
        "        # feature_map = FeatureMap()\n",
        "        # variational_circuit = VarCirc()\n",
        "        #X1 = VQC(feature_map=FeatureMap(), ansatz=VarCirc(), loss=\"cross_entropy\", optimizer= COBYLA(maxiter=50), quantum_instance=quantum_instance,)\n",
        "    #optimizer = ADAM(maxiter=30, lr=1e-3, tol = 1e-6),\n",
        "        #X1 = self.output_layer(X1)\n",
        "        #print(Y1)\n",
        "        #print(Y1.shape)\n",
        "        Y1=torch.stack(Y1)\n",
        "        #print(Y1.shape)\n",
        "        return Y1"
      ],
      "metadata": {
        "id": "qIFhO-FCpMF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iMPelpnPjA6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the neural network\n",
        "net = MyNeuralNetwork()\n",
        "# Define a loss function and an optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0.001)\n",
        "\n",
        "# Training the neural network\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(data)\n",
        "    # print(outputs)\n",
        "    # print(outputs.shape)\n",
        "    #print(labels.shape)\n",
        "    Z=torch.squeeze(outputs, 1)\n",
        "    #Z = Z.type(torch.int32)\n",
        "    # print(Z)\n",
        "    # print(Z.shape)\n",
        "    #T = torch.targets(100, 1,3)\n",
        "    #torch.reshape(torch.targets, (100, 1, 3))\n",
        "    targets=torch.tensor(targets)\n",
        "    # print(targets)\n",
        "    # print(targets.shape)\n",
        "    loss = criterion(Z, targets)\n",
        "    loss = Variable(loss, requires_grad = True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "    #loss_list_train.append(loss.clone())\n",
        "    #accuracy_list_train.append(accuracy/100)"
      ],
      "metadata": {
        "id": "axI2fI5JNrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zero_tensor(num_qubits, d):\n",
        "  psi_0 = []\n",
        "  for j in range(num_qubits):\n",
        "    k = torch.zeros((d,d,2), dtype=torch.cfloat)\n",
        "    k[0,0,0] = 1.0\n",
        "    psi_0.append(k)\n",
        "  return psi_0"
      ],
      "metadata": {
        "id": "TkUV_X_-5D60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UoLSOE_UKpyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "#X=X[y!=2]\n",
        "#y=y[y!=2]\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "# which is importance for convergence of the neural network\n",
        "#scaler = StandardScaler()\n",
        "scaler = MinMaxScaler((-3.142, 3.142))\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=2)"
      ],
      "metadata": {
        "id": "CjoX3A2E5D_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "To9yVi7IKJCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "JCVgCY2NKQy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 4\n",
        "num_layers = 1\n",
        "bond = 16"
      ],
      "metadata": {
        "id": "Z6NzSKOgtSu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzKBLPbIKFoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = VQC(num_qubits,num_layers)\n",
        "optimizer = torch.optim.Adam(model_test.parameters(), lr = 0.01, weight_decay=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "EPOCHS = 25\n",
        "X_train = (torch.from_numpy(X_train_0)).float()\n",
        "y_train = (torch.from_numpy(y_train_0)).long().reshape(X_train.shape[0],1)\n",
        "X_test  = Variable(torch.from_numpy(X_test_0)).float()\n",
        "y_test  = Variable(torch.from_numpy(y_test_0)).long().reshape(X_test.shape[0],1)\n",
        "model_test.train()\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "accuracy_list_train = np.zeros((EPOCHS,))\n",
        "\n",
        "for epoch in tqdm.trange(EPOCHS):\n",
        "  l = 0\n",
        "  c = []\n",
        "  for b,s in enumerate(X_train):\n",
        "    psi = create_zero_tensor(num_qubits, bond)\n",
        "    k1 = F.softmax(model_test(psi,s), dim = 1)\n",
        "    loss = F.cross_entropy(k1, y_train[b])\n",
        "    correct = (torch.argmax(k1, dim=1) == y_train[b]).type(torch.FloatTensor)\n",
        "    c.append(correct.item())\n",
        "    l+=loss/4\n",
        "    if int((b+1)%4)==0:\n",
        "      optimizer.zero_grad()\n",
        "      l.backward(create_graph = True)\n",
        "      optimizer.step()\n",
        "      loss_list[epoch] = l.item()\n",
        "      loss_epoch = float(l)\n",
        "      l=torch.zeros(1)\n",
        "    accuracy_list_train[epoch] = np.array(c).mean()\n",
        "  with torch.no_grad():\n",
        "    c=[]\n",
        "    for j,s in enumerate(X_test):\n",
        "      psi = create_zero_tensor(num_qubits, bond)\n",
        "      k1 = F.softmax(model_test(psi,s), dim = 1)\n",
        "      correct = (torch.argmax(k1, dim=1) == y_test[j]).type(torch.FloatTensor)\n",
        "      c.append(correct.item())\n",
        "    accuracy_list[epoch] = np.array(c).mean()\n",
        "  print(\"Train Loss: {0:1.4f}; Train Accuracy: {1:1.4f}; Test Accuracy: {2:1.4f}\".format(loss_epoch, accuracy_list_train[epoch], accuracy_list[epoch]))\n"
      ],
      "metadata": {
        "id": "xBVRKl0OJvea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26e7bf0-b833-4428-b288-22de4ade029d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1151.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  4%|▍         | 1/25 [00:02<00:51,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0919; Train Accuracy: 0.4375; Test Accuracy: 0.6316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 2/25 [00:04<00:48,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0891; Train Accuracy: 0.4464; Test Accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 3/25 [00:06<00:46,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0871; Train Accuracy: 0.4286; Test Accuracy: 0.5789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 4/25 [00:08<00:43,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0855; Train Accuracy: 0.4286; Test Accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 5/25 [00:14<01:11,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0839; Train Accuracy: 0.4554; Test Accuracy: 0.5789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 6/25 [00:16<00:58,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0824; Train Accuracy: 0.5089; Test Accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 7/25 [00:18<00:49,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0811; Train Accuracy: 0.5089; Test Accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 8/25 [00:20<00:43,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0801; Train Accuracy: 0.5179; Test Accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 9/25 [00:22<00:37,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0794; Train Accuracy: 0.5268; Test Accuracy: 0.5789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 10/25 [00:24<00:33,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0789; Train Accuracy: 0.4643; Test Accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 11/25 [00:27<00:34,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0787; Train Accuracy: 0.4732; Test Accuracy: 0.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 12/25 [00:30<00:32,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0787; Train Accuracy: 0.5179; Test Accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 13/25 [00:33<00:32,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0788; Train Accuracy: 0.5268; Test Accuracy: 0.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 14/25 [00:36<00:28,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0787; Train Accuracy: 0.5089; Test Accuracy: 0.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 15/25 [00:38<00:24,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0782; Train Accuracy: 0.5089; Test Accuracy: 0.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 16/25 [00:40<00:21,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0772; Train Accuracy: 0.5000; Test Accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 17/25 [00:43<00:20,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0757; Train Accuracy: 0.4911; Test Accuracy: 0.4737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 18/25 [00:45<00:17,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0740; Train Accuracy: 0.4643; Test Accuracy: 0.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 19/25 [00:47<00:14,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0721; Train Accuracy: 0.4464; Test Accuracy: 0.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 20/25 [00:49<00:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0701; Train Accuracy: 0.4554; Test Accuracy: 0.4737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 21/25 [00:52<00:09,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0677; Train Accuracy: 0.4554; Test Accuracy: 0.4737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 22/25 [00:55<00:07,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0650; Train Accuracy: 0.4464; Test Accuracy: 0.4737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 23/25 [00:58<00:05,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0615; Train Accuracy: 0.5268; Test Accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 24/25 [01:00<00:02,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0571; Train Accuracy: 0.5804; Test Accuracy: 0.5789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0516; Train Accuracy: 0.5714; Test Accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kx5kcBFJmx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}